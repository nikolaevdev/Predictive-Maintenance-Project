"""
–°—Ç—Ä–∞–Ω–∏—Ü–∞ ¬´–ê–Ω–∞–ª–∏–∑ –∏ –º–æ–¥–µ–ª—å¬ª.

‚Ä¢ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (UCI AI4I 2020 –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π CSV)
‚Ä¢ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ColumnTransformer ‚Üí SMOTE
‚Ä¢ –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ HalvingGridSearchCV
‚Ä¢ –ú–µ—Ç—Ä–∏–∫–∏ + –≥—Ä–∞—Ñ–∏–∫–∏
‚Ä¢ –ü–µ—Ä–µ–¥–∞—á–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ st.session_state –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á—ë—Ç–∞
"""

from __future__ import annotations
import streamlit as st
import pandas as pd
import numpy as np
from ucimlrepo import fetch_ucirepo

# --- scikit-learn / imbalanced-learn -------------------------
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import train_test_split, HalvingGridSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import (
    balanced_accuracy_score, roc_auc_score,
    classification_report, confusion_matrix, RocCurveDisplay
)
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# ---------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã --------------------------
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –∏ –º–æ–¥–µ–ª—å", layout="wide")
st.title("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")

# =============================================================
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# =============================================================
@st.cache_data(show_spinner="–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç‚Ä¶")
def load_data(path: str | None = None) -> pd.DataFrame:
    if path is None:
        ds = fetch_ucirepo(id=601)                   # AI4I 2020
        return pd.concat([ds.data.features, ds.data.targets], axis=1)
    return pd.read_csv(path)

user_csv = st.file_uploader("üíæ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–π CSV (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)", type="csv")
df = load_data(user_csv)

st.subheader("–§—Ä–∞–≥–º–µ–Ω—Ç –≤—ã–±–æ—Ä–∫–∏")
st.dataframe(df.head())

# =============================================================
# 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ ¬´—Å–ª—É–∂–µ–±–Ω—ã—Ö¬ª –∫–æ–ª–æ–Ω–æ–∫)
# =============================================================
cols_to_drop = ["UDI", "Product ID", "TWF", "HDF", "PWF", "OSF", "RNF"]
df = df.drop(columns=cols_to_drop, errors="ignore")   # errors='ignore'

# –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è ‚Äî –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ –≤—ã–±–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
DEFAULT_TARGET = "Machine failure"
TARGET = DEFAULT_TARGET if DEFAULT_TARGET in df.columns else st.sidebar.selectbox(
    "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è", df.columns, index=len(df.columns)-1
)

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ / —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
categorical = [c for c in ["Type"] if c in df.columns]
numeric = [c for c in df.columns if c not in categorical + [TARGET]]

preprocessor = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical),
        ("num", StandardScaler(),                     numeric),
    ],
    verbose_feature_names_out=False,
)

# =============================================================
# 3. –í—ã–±–æ—Ä –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∏ —Å–µ—Ç–æ–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
# =============================================================
model_name = st.sidebar.selectbox(
    "–ê–ª–≥–æ—Ä–∏—Ç–º",
    ("LogisticRegression", "RandomForest", "XGBoost"),
)

def make_estimator(name: str):
    if name == "LogisticRegression":
        return LogisticRegression(max_iter=1000, n_jobs=-1, solver="lbfgs")
    if name == "RandomForest":
        return RandomForestClassifier(random_state=42, n_jobs=-1)
    if name == "XGBoost":
        return XGBClassifier(
            objective="binary:logistic",
            tree_method="hist",
            colsample_bytree=0.8, subsample=0.8,
            random_state=42, n_jobs=-1,
        )
    raise ValueError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º")

param_grids = {
    "LogisticRegression": {
        "clf__C": np.logspace(-3, 2, 6),
        "clf__class_weight": ["balanced"],
    },
    "RandomForest": {
        "clf__n_estimators": [200, 500],
        "clf__max_depth":    [None, 10, 20],
        "clf__class_weight": ["balanced"],
    },
    "XGBoost": {
        "clf__n_estimators":     [300, 500],
        "clf__learning_rate":    [0.03, 0.1],
        "clf__max_depth":        [3, 6],
        "clf__scale_pos_weight": [10],
    },
}

# =============================================================
# 4. Pipeline
# =============================================================

pipe = ImbPipeline(
    steps=[
        ("prep",  preprocessor),
        ("smote", SMOTE(random_state=42)),
        ("clf",   make_estimator(model_name)),
    ]
)

X = df.drop(columns=[TARGET])
y = df[TARGET]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

with st.spinner("–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å‚Ä¶"):
    search = HalvingGridSearchCV(
        pipe,
        param_grid=param_grids[model_name],
        scoring="roc_auc",
        factor=3,
        cv=5,
        n_jobs=-1,
        verbose=0,
    )
    search.fit(X_train, y_train)

best_model = search.best_estimator_
joblib.dump(best_model, "best_model.joblib")

st.success("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

# =============================================================
# 5. –ú–µ—Ç—Ä–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
# =============================================================
y_pred  = best_model.predict(X_test)
y_proba = best_model.predict_proba(X_test)[:, 1]

roc_auc = roc_auc_score(y_test, y_proba)
bal_acc = balanced_accuracy_score(y_test, y_pred)

st.subheader("–ú–µ—Ç—Ä–∏–∫–∏")
m1, m2 = st.columns(2)
m1.metric("ROC-AUC", f"{roc_auc:.3f}")
m2.metric("Balanced accuracy", f"{bal_acc:.3f}")

with st.expander("Classification report"):
    st.code(classification_report(y_test, y_pred), language="text")

fig_cm, ax_cm = plt.subplots()
sns.heatmap(confusion_matrix(y_test, y_pred),
            annot=True, fmt="d", cmap="Blues", ax=ax_cm)
ax_cm.set_xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
ax_cm.set_ylabel("–ò—Å—Ç–∏–Ω–∞")
st.pyplot(fig_cm)

fig_roc, ax_roc = plt.subplots()
RocCurveDisplay.from_predictions(y_test, y_proba, ax=ax_roc)
ax_roc.set_title("ROC-–∫—Ä–∏–≤–∞—è")
st.pyplot(fig_roc)

# =============================================================
# 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç—á—ë—Ç–∞
# =============================================================
st.session_state["report"] = {
    "model":       model_name,
    "best_params": search.best_params_,
    "roc_auc":     roc_auc,
    "bal_acc":     bal_acc,
}
